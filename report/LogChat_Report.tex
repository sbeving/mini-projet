\documentclass[12pt, a4paper]{report}

% =========================================================================
% PACKAGES
% =========================================================================
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{titlesec}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{array}
\usepackage{fancyhdr}
\usepackage{tocbibind}
\usepackage[backend=biber, style=ieee]{biblatex}
\usepackage{csquotes}
\usepackage{tcolorbox} % For "Beginner Note" boxes
\usepackage{enumitem}

\addbibresource{references.bib}

% =========================================================================
% PAGE CONFIGURATION
% =========================================================================
\geometry{
    a4paper, 
    left=25mm, 
    right=25mm, 
    top=25mm, 
    bottom=25mm
}
\linespread{1.5} % Good for length and readability

% Header/Footer
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\slshape \rightmark}
\fancyhead[R]{\thepage}
\renewcommand{\headrulewidth}{0.4pt}

% Colors
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\definecolor{infoboxcolor}{rgb}{0.9,0.95,1.0}

% Code Listing Style
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}

% Command for Placeholder Images
\newcommand{\placeholderImage}[2]{
    \begin{figure}[H]
        \centering
        \fbox{
            \begin{minipage}{0.9\textwidth}
                \centering
                \vspace{2cm}
                \textbf{PLACEHOLDER FOR:} #1 \\
                \textit{(Screenshot/Diagram)}
                \vspace{2cm}
            \end{minipage}
        }
        \caption{#2}
        \label{fig:#1}
    \end{figure}
}

% Beginner Friendly Note Box
\newtcolorbox{infobox}[1]{
    colback=infoboxcolor,
    colframe=blue!30!black,
    title=\textbf{#1},
    fonttitle=\bfseries
}

% =========================================================================
% DOCUMENT BEGINS
% =========================================================================
\begin{document}

% -------------------------------------------------------------------------
% TITLE PAGE
% -------------------------------------------------------------------------
\begin{titlepage}
    \begin{center}
        \includegraphics[width=4cm]{placeholder_logo.png} \\ % Placeholder for uni/project logo
        \vspace{1cm}
        {\Large \textbf{Higher Institute of Technological Studies}}\\[0.5cm]
        {\large Department of Computer Technologies}\\[2cm]

        {\Huge \textbf{LogChat: AI-Powered SIEM Platform}}\\[0.5cm]
        {\Large \textit{An Intelligent Security Information and Event Management System}}\\[2cm]

        \textbf{End of Year Project Report}\\[2cm]

        \begin{minipage}{0.4\textwidth}
            \begin{flushleft} \large
                \emph{Authors:}\\
                Saleh Eddine \textsc{Touil}\\
                Chames Edin \textsc{Turki}
            \end{flushleft}
        \end{minipage}
        \begin{minipage}{0.4\textwidth}
            \begin{flushright} \large
                \emph{Supervisor:}\\
                Mr. Mounir \textsc{Kthiri}
            \end{flushright}
        \end{minipage}

        \vfill
        {\large Academic Year: 2024 - 2025}
    \end{center}
\end{titlepage}

% -------------------------------------------------------------------------
% FRONT MATTER
% -------------------------------------------------------------------------
\section*{Dedication}
\textit{To our families, for their endless support and coffee supplies. To the open-source community, for giving us the blocks to build our castle.}
\newpage

\section*{Acknowledgements}
We would like to express our deepest gratitude to our supervisor, Mr. Mounir Kthiri, for his guidance, patience, and technical insights throughout this project.
We also thank our friends and colleagues who helped test the platform and provided valuable feedback.
\newpage

\section*{Abstract}
In the modern cybersecurity landscape, logs are generated at an unprecedented rate. Traditional Security Information and Event Management (SIEM) systems are often expensive, complex to deploy, and lack intuitive interfaces for non-expert users.

\textbf{LogChat} addresses this gap by combining a robust logging architecture with the power of Generative AI (Large Language Models). Built with Next.js, Node.js, and PostgreSQL, and integrated with Ollama (local LLM), LogChat allows security analysts to "chat" with their logs. Instead of writing complex SQL or KQL queries, users can ask "What security threats happened today?" and receive an AI-synthesized answer based on real database records.

This report details the full development lifecycle, from state-of-the-art analysis and requirements gathering to architectural design, full-stack implementation, and containerized deployment.

\vspace{1cm}
\textbf{Keywords:} SIEM, Cybersecurity, Artificial Intelligence, LLM, RAG, React, Docker, Threat Detection.
\newpage

\tableofcontents
\listoffigures
\listoftables
\newpage

% -------------------------------------------------------------------------
% GENERAL INTRODUCTION
% -------------------------------------------------------------------------
\chapter*{General Introduction}
\addcontentsline{toc}{chapter}{General Introduction}

\section*{Context}
Every server, application, and network device generates "logs"—records of what happened, when, and by whom. In small systems, a system administrator might manually read a text file to check for errors. However, in enterprise environments generating millions of logs per hour, manual inspection is impossible. This is where \textbf{SIEM} (Security Information and Event Management) systems come in. They aggregate logs, detect patterns, and alert administrators to threats.

However, a new problem has emerged: "Alert Fatigue" and high technical barriers. Using tools like Splunk or ELK Stack requires learning complex query languages. If an attacker breaches a system, finding the needle in the haystack requires expertise.

\section*{Problem Statement}
\begin{itemize}
    \item \textbf{High Complexity:} Existing tools are hard to configure and query.
    \item \textbf{Data Overload:} Security teams are overwhelmed by raw data without context.
    \item \textbf{Lack of AI Integration:} Most open-source SIEMs rely on static rule-matching (Regular Expressions) and lack semantic understanding of threats.
\end{itemize}

\section*{Proposed Solution: LogChat}
Our project, \textbf{LogChat}, proposes a paradigm shift. Instead of just searching logs, you verify them with an AI.
\begin{itemize}
    \item \textbf{Centralized Logging:} A HTTP API to ingest logs from any source.
    \item \textbf{Real-time Dashboards:} Visualizing system health and security events.
    \item \textbf{Threat Engine:} Automatic rule-based tagging of logs (e.g., stopping SQL Injection attempts).
    \item \textbf{RAG Chatbot:} A "Retrieval Augmented Generation" system where an AI answers questions using your live log data as context.
\end{itemize}

\section*{Report Structure}
This report is organized into four main chapters:
\begin{enumerate}
    \item \textbf{State of the Art:} Comparing existing solutions and selecting technologies.
    \item \textbf{Analysis and Design:} Detailed requirements, UML diagrams, and architecture.
    \item \textbf{Implementation:} Deep dive into the code, database interaction, and AI integration.
    \item \textbf{Testing and Deployment:} Validating the system quality and deploying via Docker.
\end{enumerate}

\begin{infobox}{Beginner Concept: What is a Log?}
    A log is like a "black box" recording for computers. It is a text message that a program writes when something occurs. For example:
    \texttt{[2024-05-20 10:00:00] [ERROR] User 'admin' failed to login (Wrong Password).}
    Collecting these helps us detect hackers!
\end{infobox}

\cleardoublepage

% =========================================================================
% CHAPTER 1: STATE OF THE ART
% =========================================================================
\chapter{State of the Art}

\section{Introduction}
Before building LogChat, we must understand the current landscape of logging and security monitoring tools. This chapter explores market leaders, theoretical concepts of SIEM, and justifies our technology choices.

\section{Understanding SIEM Systems}
SIEM stands for \textbf{Security Information and Event Management}. It aggregates log data from various sources (servers, firewalls, applications), identifies patterns that signify threats, and alerts security teams.

\begin{infobox}{What does a SIEM do?}
    Imagine a security guard watching 100 CCTV cameras at once. A SIEM is the computer that automatically beeps when it sees someone breaking a window on Camera 42.
\end{infobox}

\section{Existing Solutions Comparison}

\subsection{Splunk}
Splunk is the market leader. It allows capturing, indexing, and correlating real-time data in a searchable repository.
\begin{itemize}
    \item \textbf{Pros:} extremely powerful, vast ecosystem of plugins, beautiful dashboards.
    \item \textbf{Cons:} Extremely expensive (proprietary license), high hardware requirements, steep learning curve (SPL language).
\end{itemize}

\subsection{ELK Stack (Elasticsearch, Logstash, Kibana)}
The Elastic Stack is the most popular open-source option.
\begin{itemize}
    \item \textbf{Pros:} Open-source core, scalable, industry standard.
    \item \textbf{Cons:} Very resource-heavy (Java-based), complex to manage at scale, no built-in "AI Chat".
\end{itemize}

\subsection{Wazuh}
Wazuh is an open-source security platform (unifying XDR and SIEM).
\begin{itemize}
    \item \textbf{Pros:} Great for endpoint security, pre-configured rules.
    \item \textbf{Cons:} UI can be clunky, focused more on Host IDS than application logs.
\end{itemize}

\subsection{Comparison Table}
\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Feature} & \textbf{Splunk} & \textbf{ELK Stack} & \textbf{LogChat (Ours)} \\ \hline
License & Commercial & Open Core & MIT (Open Source) \\ \hline
Cost & \$\$\$\$ & \$\$ (Hosting) & \$ (Low Resource) \\ \hline
AI Integration & Add-on & ML Nodes & \textbf{Native Core Feature} \\ \hline
Ease of Use & Hard & Medium & \textbf{Easy (Chat-based)} \\ \hline
Architecture & Proprietary & Java/NoSQL & Node.js/PostgreSQL \\ \hline
\end{tabular}
\caption{Comparison of SIEM Solutions}
\end{table}

\section{The Rise of Generative AI in Ops}
The newest trend in 2024 is \textbf{AIOps}. Large Language Models (LLMs) like GPT-4 or Llama 3 can understand code and logs. By integrating an LLM, we lower the barrier to entry. This technique is often called **RAG** (Retrieval Augmented Generation).

\begin{infobox}{What is RAG?}
    LLMs (like ChatGPT) don't know your private data. RAG is a technique where we search your database for relevant info first, then give it to the AI saying "Use this info to answer the user's question."
\end{infobox}

\section{Technology Stack Selection}
For LogChat, we chose a modern, lightweight, and JavaScript-centric stack.

\subsection{Frontend: Next.js 14}
\begin{itemize}
    \item \textbf{Why?} React-based framework with Server Side Rendering (SSR). Excellent performance and developer experience.
    \item \textbf{Role:} Admin Dashboard, Real-time Charts, Chat Interface.
\end{itemize}

\subsection{Backend: Node.js \& Express}
\begin{itemize}
    \item \textbf{Why?} Fast I/O, perfect for handling thousands of log requests per minute. Same language (TypeScript) as frontend.
    \item \textbf{Role:} API endpoints, Threat Detection Logic, Auth.
\end{itemize}

\subsection{Database: PostgreSQL \& Prisma}
\begin{itemize}
    \item \textbf{Why?} Reliability. SQL is structured and powerful for analytics. Prisma provides type-safe database access.
    \item \textbf{Role:} Storing User profiles, Log events, and Chat history.
\end{itemize}

\subsection{AI Engine: Ollama}
\begin{itemize}
    \item \textbf{Why?} Runs LLMs \textbf{locally}. We don't want to send sensitive security logs to the cloud (privacy risk).
    \item \textbf{Role:} Processing natural language queries into insights.
\end{itemize}

\section{Development Methodology: SCRUM}
We adopted an Agile SCRUM approach.
\begin{itemize}
    \item \textbf{Sprints:} 1-week cycles.
    \item \textbf{Daily Standups:} Brief Discord calls to sync on progress.
    \item \textbf{Tools:} Trello for Kanban, GitHub for version control.
\end{itemize}

\placeholderImage{gantt_chart.png}{Project Gantt Chart Timeline}

\section{Conclusion}
We have identified a gap in the market for a lightweight, AI-first SIEM. We have selected a robust stack (Next.js/Node/Postgres/Ollama) to build it. Next, we will analyze the specific requirements.

\cleardoublepage

% =========================================================================
% CHAPTER 2: ANALYSIS AND DESIGN
% =========================================================================
\chapter{Analysis and Design}

\section{Introduction}
This chapter bridges the gap between the idea and the code. We define \textit{what} the system must do (requirements) and \textit{how} it will be structured (architecture).

\section{Feasibility Study}
Before commencing development, we analyzed the feasibility of the project:
\begin{itemize}
    \item \textbf{Technical Feasibility:} The chosen stack (Node/Next/Postgres) is mature. The AI component (Ollama) is experimental but proven to work on consumer hardware with 8GB+ RAM.
    \item \textbf{Operational Feasibility:} The system is designed to be "Docker-first", meaning deployment is standardized across environments.
    \item \textbf{Economic Feasibility:} Utilizing open-source software (OSS) eliminates licensing costs, making this accessible for SMEs.
\end{itemize}

\section{Requirement Specification}

\subsection{Functional Requirements}
Functionalities the user interacts with directly:
\begin{enumerate}
    \item \textbf{Log Ingestion Module:}
    \begin{itemize}
        \item The system must expose a REST API to accept logs in JSON format.
        \item Validates incoming data against a schema (Zod).
        \item Rejects malformed requests with 400 Bad Request.
    \end{itemize}
    \item \textbf{Threat Detection Engine:}
    \begin{itemize}
        \item Incoming logs must be scanned against a library of RegEx patterns.
        \item Automatically tag logs with severity (INFO, WARNING, HIGH, CRITICAL).
    \end{itemize}
    \item \textbf{Analyst Dashboard:}
    \begin{itemize}
        \item Display real-time counters for Total Logs, Error Rates, and Threat Levels.
        \item Visualize log volume trends over time (Line Chart).
        \item Show distribution of logs by service (Pie/Bar Chart).
    \end{itemize}
    \item \textbf{AI Chat Assistant (RAG):}
    \begin{itemize}
        \item Users must be able to ask questions in plain English.
        \item The system must retrieve relevant recent logs to inject as context.
        \item Supports "Conversation Memory" (remembering previous questions).
    \end{itemize}
    \item \textbf{User Management:}
    \begin{itemize}
        \item Admin can create analyst accounts.
        \item Role-based protection (Admins can delete logs; Analysts can only view).
    \end{itemize}
\end{enumerate}

\subsection{Non-Functional Requirements}
Qualities of the system:
\begin{enumerate}
    \item \textbf{Performance:}
    \begin{itemize}
        \item API Response time < 50ms for ingestion.
        \item Dashboard load time < 1s.
        \item Support at least 100 concurrent log requests/second.
    \end{itemize}
    \item \textbf{Security:}
    \begin{itemize}
        \item All API endpoints protected by JWT (JSON Web Tokens).
        \item Passwords hashed using bcrypt (salt rounds = 10).
        \item No sensitive data (API keys) exposed in frontend bundles.
    \end{itemize}
    \item \textbf{Usability:}
    \begin{itemize}
        \item Interface must follow "clean UI" principles (shadcn/ui style).
        \item Dark mode support for eye comfort in SOC (Security Operations Center) environments.
        \item Mobile-responsive layout.
    \end{itemize}
    \item \textbf{Privacy:}
    \begin{itemize}
        \item \textbf{Local AI Processing:} No log data shall be sent to external APIs (like OpenAI). All inference happens on the local server via Ollama.
    \end{itemize}
\end{enumerate}

\section{Data Dictionary}
To ensure consistent data structures, we defined the following core entities:

\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|l|}
    \hline
    \textbf{Entity} & \textbf{Field} & \textbf{Description} \\ \hline
    \textbf{Log} & \texttt{id} (UUID) & Unique identifier for the event. \\ \hline
     & \texttt{level} (Enum) & INFO, WARN, ERROR, CRITICAL. \\ \hline
     & \texttt{message} (String) & The content of the log (e.g., "Failed login"). \\ \hline
     & \texttt{source} (String) & The service name (e.g., "Payment-API"). \\ \hline
     & \texttt{metadata} (JSON) & Extra details (IP address, user agents). \\ \hline
    \textbf{User} & \texttt{role} (Enum) & ADMIN, USER, AUDITOR. \\ \hline
    \textbf{Audit} & \texttt{action} (String) & What the user did (e.g., "DELETED\_LOG"). \\ \hline
    \end{tabular}
    \caption{Data Dictionary for Core Entities}
\end{table}

\section{Use Case Analysis}
The Use Case diagram identifies the main actors and their interactions.

\subsection{Actors}
\begin{itemize}
    \item \textbf{Security Analyst (User):} The primary operator. Reviews logs, investigates alerts, chats with AI.
    \item \textbf{Administrator:} Has elevated privileges. Can configure system sources, manage users, and flush databases.
    \item \textbf{External System (Log Source):} A server, container, or application sending log data automatically via the Agent.
\end{itemize}

\subsection{Global Use Case Diagram}
\placeholderImage{usecase_global.png}{Global Use Case Diagram}
\textit{The diagram illustrates the central role of the Platform in mediating between Human Analysts and Machine Data sources.}

\section{System Architecture}
We chose a \textbf{Dockerized Microservices-like} architecture. While essentially a monolith in logic, the services are containerized separately.

\subsection{Component Diagram}
The architecture separates the User Interface from the Logic and Data to allow independent scaling.

\placeholderImage{architecture_component.png}{System Component Architecture}

\subsection{Architectural Decisions}
\begin{itemize}
    \item \textbf{Why Next.js App Router?} It merges the Backend-for-Frontend (BFF) pattern with the UI, simplifying data fetching.
    \item \textbf{Why Prisma?} It provides type safety. If the database schema changes, the frontend code fails at compile time, preventing runtime errors.
    \item \textbf{Why Ollama?} It abstracts the complexity of running GGML/GGUF models (like Llama 3 or Qwen) into a simple HTTP API.
\end{itemize}

\section{Sequence Diagrams}
To understand the flow of data, we model specific scenarios.

\subsection{Scenario 1: User Login}
\placeholderImage{sequence_login.png}{Sequence Diagram: User Authentication}
The user sends credentials, the backend validates against PostgreSQL, and issues a JWT (JSON Web Token) which is stored in HTTP-Only cookies.

\subsection{Scenario 2: AI Chat (RAG Flow)}
This is the core innovation of our project and the most complex interaction.
\begin{enumerate}
    \item User asks "Show me errors".
    \item Backend receives request at \texttt{/api/chat}.
    \item \textbf{Retrieval:} Backend searches DB for recent logs where \texttt{level='ERROR'}.
    \item \textbf{Augmentation:} Backend formats a prompt: \textit{"Here are the logs: [LOG\_DATA]. Q: Show me errors"}.
    \item \textbf{Generation:} Ollama receives the huge prompt and generates a summary.
    \item Backend returns the synthesized text to UI.
\end{enumerate}

\placeholderImage{sequence_chat_rag.png}{Sequence Diagram: AI Chat Interaction}

\section{Activity Diagrams}
How does the "Threat Engine" decide if a log is dangerous? This logic runs synchronously for every incoming HTTP POST.

\placeholderImage{activity_threat_detection.png}{Activity Diagram: Log Ingestion \& Threat Logic}

\section{Database Design}
We use a relational model. 

\subsection{Entities}
\begin{itemize}
    \item \textbf{User:} \texttt{id, email, password\_hash, role}
    \item \textbf{Log:} \texttt{id, timestamp, level, message, metadata (JSON)}
    \item \textbf{ChatSession:} \texttt{id, user\_id, title}
    \item \textbf{Message:} \texttt{id, session\_id, role (user/ai), content}
\end{itemize}

\subsection{Class Diagram}
\placeholderImage{class_diagram_domain.png}{Domain Class Diagram}

\section{Conclusion}
We have mapped out the requirements and modeled the system using UML. The design prioritizes modularity and data flow efficiency.

\cleardoublepage

% =========================================================================
% CHAPTER 3: IMPLEMENTATION
% =========================================================================
\chapter{Implementation}

\section{Introduction}
This chapter takes a deep dive into the code. We will explore the backend logic for threat detection, the frontend React components for visualization, and the integration with the Ollama AI model.

\section{Project Structure}
The project is organized as a monorepo containing both the Frontend and Backend services.

\begin{lstlisting}[language=bash]
/logchat
|-- backend/
|   |-- src/
|   |   |-- index.ts          # Express App Entry point
|   |   |-- config/           # Environment variables (JWT_SECRET)
|   |   |-- middleware/       # Auth Middleware
|   |   |-- services/         # Business Logic Layer
|   |   |   |-- logs.ts       # Log storage & Filtering
|   |   |   |-- ollama.ts     # AI API Wrapper
|   |   |   |-- threats.ts    # Regex Pattern Matcher
|   |   |-- routes/           # REST API Definitions
|   |-- prisma/               # Database Schema (ORM)
|   |-- Dockerfile            # Container definition
|
|-- frontend/
|   |-- app/                  # Next.js 14 App Router
|   |   |-- dashboard/        # Protected Dashboard routes
|   |   |-- chat/             # Chat Interface route
|   |-- components/           # Reusable UI Components
|   |   |-- ui/               # Shadcn/UI primitives (Button, Card)
|   |   |-- LogsChart.tsx     # Recharts Visualization
|   |   |-- LogTable.tsx      # Data Table
|   |-- lib/                  # Utility functions
|   |-- Dockerfile
|
|-- docker-compose.yml        # Orchestration Config
\end{lstlisting}

\section{Backend Implementation}
The backend uses **Express.js** for its simplicity and speed.

\subsection{Data Access Layer (Prisma)}
We chose Prisma as our ORM (Object-Relational Mapper). It allows us to define our schema in a readable format (`schema.prisma`) and handles all SQL migrations automatically.

\begin{lstlisting}[language=JavaScript, caption=Prisma Schema Definition]
// prisma/schema.prisma

model Log {
  id        String   @id @default(uuid())
  level     String   // INFO, WARN, ERROR, CRITICAL
  message   String
  source    String   // Service Name (e.g., 'PaymentGateway')
  timestamp DateTime @default(now())
  metadata  Json?    // Flexible JSON storage for headers/IPs

  @@index([timestamp]) // Index for faster range queries
  @@index([level])     // Index for faster filtering
}

model User {
  id            String   @id @default(uuid())
  email         String   @unique
  passwordHash  String
  role          String   @default("USER")
}
\end{lstlisting}

\subsection{Role of the Threat Engine}
This service acts as a middleware for incoming logs. Before a log is saved, it passes through `scanLog()`.

\begin{lstlisting}[language=JavaScript, caption=Threat Detection Logic (backend/src/services/threats.ts)]
// Pre-compiled regex for performance
const THREAT_PATTERNS = [
  { 
    name: 'SQL_INJECTION', 
    regex: /(\%27)|(\')|(\-\-)|(\%23)|(#)/i, 
    level: 'CRITICAL' 
  },
  { 
    name: 'XSS_ATTEMPT', 
    regex: /((%3C)|<)((%2F)|\/)*[a-z0-9%]+((%3E)|>)/i, 
    level: 'HIGH' 
  }
];

export function scanLog(message: string) {
  for (const p of THREAT_PATTERNS) {
    if (p.regex.test(message)) {
      return { 
        detected: true, 
        type: p.name, 
        severity: p.level 
      };
    }
  }
  return { detected: false };
}
\end{lstlisting}

\subsection{API Endpoints}
We expose RESTful endpoints documented below:

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Method} & \textbf{Endpoint} & \textbf{Description} \\ \hline
POST & \texttt{/api/auth/login} & Returns JWT token. \\ \hline
GET & \texttt{/api/logs} & Returns paginated logs. Supports ?level=ERROR. \\ \hline
POST & \texttt{/api/logs/ingest} & Internal endpoint for agents to push logs. \\ \hline
POST & \texttt{/api/chat} & RAG Endpoint. Sends question to Ollama. \\ \hline
\end{tabular}
\caption{Key API Endpoints}
\end{table}

\section{AI Integration (Ollama)}
The integration with the Large Language Model is handled in `services/ollama.ts`. We use the `axios` library to call the Ollama local API.

\begin{lstlisting}[language=JavaScript, caption=Connecting to Ollama]
import axios from "axios";

const OLLAMA_URL = process.env.OLLAMA_HOST || "http://ollama:11434";

export async function askAI(prompt: string, context: string) {
  try {
    const response = await axios.post(`${OLLAMA_URL}/api/generate`, {
      model: "qwen2.5:0.5b", // We use a small model for speed
      prompt: `CONTEXT:\n${context}\n\nUSER QUESTION:\n${prompt}`,
      stream: false
    });
    return response.data.response;
  } catch (error) {
    console.error("AI Service Error:", error);
    return "I'm sorry, I cannot access the brain right now.";
  }
}
\end{lstlisting}

\section{Frontend Implementation}
The frontend acts as the control center.

\subsection{Dashboard \& Data Visualization}
We use **Recharts** for drawing graphs. The data flow is:
1. `StatsCards` component fetches summary numbers.
2. `LogsChart` component fetches time-series data.

\placeholderImage{dashboard_full.png}{Full Admin Dashboard with Dark Mode}

\subsection{Live Log Viewer}
The log table supports real-time updates. We use a polling mechanism (refreshing every 5 seconds) to keep the display fresh without overloading the server with WebSockets.

\begin{lstlisting}[language=JavaScript, caption=React Log Table with Highlighting]
export default function LogTable({ logs }) {
  return (
    <div className="rounded-md border">
      <Table>
        <TableHeader>
           <TableRow>
             <TableHead>Timestamp</TableHead>
             <TableHead>Level</TableHead>
             <TableHead>Message</TableHead>
           </TableRow>
        </TableHeader>
        <TableBody>
          {logs.map((log) => (
            <TableRow key={log.id} 
              className={log.level === 'ERROR' ? 'bg-red-950/20' : ''}>
              <TableCell>{format(log.timestamp, "HH:mm:ss")}</TableCell>
              <TableCell>
                <Badge variant={log.level}>{log.level}</Badge>
              </TableCell>
              <TableCell className="font-mono">{log.message}</TableCell>
            </TableRow>
          ))}
        </TableBody>
      </Table>
    </div>
  );
}
\end{lstlisting}

\subsection{Chat Interface (Chatbot.tsx)}
The chat interface maintains a local state array `messages[]`. When the user types:
1. The message is pushed to the array with `role: 'user'`.
2. A loading spinner appears.
3. The API call is made to the backend.
4. The response is pushed with `role: 'ai'`.

\placeholderImage{chat_interface.png}{Chat Interface interacting with Log Data}

\section{Docker Deployment Architecture}
The entire stack is defined in `docker-compose.yml`. This allows the application to be brought up with a single command.

\begin{lstlisting}[language=yaml]
version: '3.8'

services:
  backend:
    build: ./backend
    ports: ["3001:3001"]
    depends_on: [db, ollama]
    environment:
      - DATABASE_URL=postgresql://user:password@db:5432/logs

  frontend:
    build: ./frontend
    ports: ["3000:3000"]

  ollama:
    image: ollama/ollama
    volumes:
      - ollama_data:/root/.ollama
    # API exposed on port 11434 by default

  db:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: logs
\end{lstlisting}

\section{Conclusion}
The implementation focuses on modularity. By using industry-standard tools like Prisma and Express, we ensure the codebase is maintainable. The Docker integration ensures that checking out the code and running it is a seamless experience.

\cleardoublepage

% =========================================================================
% CHAPTER 4: TESTING AND DEPLOYMENT
% =========================================================================
\chapter{Testing and Deployment}

\section{Introduction}
Writing code is not enough; it must be verified. This chapter covers the testing strategy and how we deploy the solution.

\section{Testing Strategy}
We employed a "Testing Pyramid" approach: Unit Tests (small), Integration Tests (connected), and Manual/E2E Tests (full flow).

\subsection{Unit Testing (Manual Verification)}
We verified the threat detection regexes individually.
\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Input String} & \textbf{Expected Result} & \textbf{Pass/Fail} \\ \hline
"User logged in" & Safe & Pass \\ \hline
"SELECT * FROM users" & SQL Injection (Critical) & Pass \\ \hline
"<script>alert(1)</script>" & XSS Threat (High) & Pass \\ \hline
\end{tabular}
\caption{Threat Engine Test Cases}
\end{table}

\subsection{Integration Testing}
We tested the API endpoints using Postman.
\begin{itemize}
    \item \textbf{POST /api/logs:} Valid JSON returns 201 Created. Invalid JSON returns 400 Bad Request.
    \item \textbf{GET /api/stats:} Verifying the counters match the number of rows in DB.
\end{itemize}

\section{Deployment Guide}
We deploy using Docker.

\placeholderImage{deployment_diagram.png}{Deployment Diagram}

\subsection{Prerequisites}
\begin{itemize}
    \item A machine with 8GB RAM (for AI model).
    \item Docker Desktop or Docker Engine installed.
\end{itemize}

\subsection{Launch Steps}
\begin{enumerate}
    \item Clone the repository.
    \item Run \texttt{docker-compose up --build}.
    \item Wait for the AI model to pull (approx 2GB).
    \item Access \texttt{localhost:3000}.
\end{enumerate}

\section{Challenges Faced}
\begin{enumerate}
    \item \textbf{LLM Latency on CPU:} Running Ollama on a laptop CPU is slow (3-4 seconds per reply). In production, a GPU is recommended.
    \item \textbf{Docker Networking:} Connecting the Backend container to the Ollama container required careful DNS configuration in docker-compose.
\end{enumerate}

\section{Future Improvements}
\begin{itemize}
    \item \textbf{Kubernetes Support:} For high availability scaling.
    \item \textbf{Fine-Tuning:} Training the specific AI model on cybersecurity datasets to improve accuracy.
    \item \textbf{Dark Mode:} Fully implementing theme switching.
\end{itemize}

\section{Conclusion}
The system is stable, easy to deploy, and meets the core requirements defined in Chapter 2.

\cleardoublepage

% =========================================================================
% CHAPTER 5: USER GUIDE (Tutorial)
% =========================================================================
\chapter{User Guide \& Walkthrough}
\label{chap:userguide}

\section{Welcome to LogChat}
This section is a pictorial guide for new users.

\section{1. The Login Screen}
When you first open the app, you must authenticate.
\placeholderImage{login_page.png}{The Secure Login Page}

\section{2. The Dashboard}
After login, you see the "Mission Control".
\placeholderImage{dashboard_after_seed.png}{Dashboard populated with data}
\begin{itemize}
    \item \textbf{Top Row:} Critical Alerts count.
    \item \textbf{Charts:} Log volume over time.
    \item \textbf{Gauge:} Access Log vs Error Log ratio.
\end{itemize}

\section{3. Exploring Logs}
Click "Logs" in the sidebar. You can filter by:
\begin{itemize}
    \item Level (Info, Error, Warn)
    \item Source (Frontend, API, Auth)
    \item Search Text
\end{itemize}
\placeholderImage{log_table_view.png}{Filtering logs for specific errors}

\section{4. Chatting with your Data}
Click "AI Assistant". Try typing: \textit{"Summarize the last 5 errors"}.
\placeholderImage{chat_first_question.png}{The AI response summarizing database rows}

\begin{infobox}{Tip: Be specific!}
    The AI works best with clear questions. Instead of "What's up?", ask "Are there any SQL injection attempts in the last hour?"
\end{infobox}

\cleardoublepage

% =========================================================================
% GENERAL CONCLUSION
% =========================================================================
\chapter*{General Conclusion}
\addcontentsline{toc}{chapter}{General Conclusion}

\section*{Summary}
This project set out to democratize access to advanced security monitoring using the latest advancements in Artificial Intelligence. We successfully built \textbf{LogChat}, a functional SIEM that allows anyone—regardless of technical skill—to query their system's security status using natural language.

\section*{Key Achievements}
\begin{itemize}
    \item \textbf{Full Stack Mastery:} Developed a complete solution using Next.js, Node.js, and Postgres.
    \item \textbf{AI Innovation:} Successfully integrated a local LLM (Ollama) into a production workflow using RAG.
    \item \textbf{User Experience:} Created a clean, intuitive interface that hides the complexity of log management.
\end{itemize}

\section*{Personal Reflections}
Working on LogChat was a journey of discovery. We learned that integrating AI is not magic; it requires rigorous data engineering (RAG) to be useful. We also gained deep appreciation for the stability of Docker in development workflows.

We believe LogChat represents the future of specialized software: tools that don't just display data, but help you \textit{understand} it.


% =========================================================================
% APPENDIX A: DIAGRAM SOURCE CODES
% =========================================================================
\appendix
\chapter{Appendix: PlantUML Source Codes}
For transparency and reproducibility, we include the source code for the diagrams used in this report. These can be rendered using any PlantUML-compatible tool.

\section{Use Case Diagram: Global}
\begin{lstlisting}
@startuml usecase_global
left to right direction
actor "Security Analyst" as Analyst
actor "System Administrator" as Admin
actor "Background System" as System

rectangle "LogChat SIEM Platform" {
    package "Core Operations" {
        usecase "Authenticate (Login/Logout)" as UC1
        usecase "View Analytics Dashboard" as UC2
        usecase "Explore & Filter Logs" as UC3
        usecase "Chat with AI Assistant" as UC4
    }

    package "Administration" {
        usecase "Manage Users & Roles" as UC5
        usecase "Configure Log Sources" as UC6
        usecase "Manage Alert Rules" as UC7
        usecase "View Audit Logs" as UC8
    }

    package "Automated Processes" {
        usecase "Ingest Logs via API" as UC9
        usecase "Detect Threats (Real-time)" as UC10
        usecase "Trigger Alerts" as UC11
    }
}

Analyst --> UC1
Analyst --> UC2
Analyst --> UC3
Analyst --> UC4
Analyst --> UC8

Admin --> UC1
Admin --> UC5
Admin --> UC6
Admin --> UC7
Admin --> UC8

System --> UC9
System --> UC10
System --> UC11
UC10 .> UC11 : <<include>>
@enduml
\end{lstlisting}

\section{Component Architecture}
\begin{lstlisting}
@startuml architecture_component
skinparam componentStyle uml2

package "Docker Container Host" {
    package "Frontend Container" {
        [Next.js App Router] as NextJS
        [React Components] as React
        [Tailwind CSS] as UI
        NextJS *-- React
        React *-- UI
    }

    package "Backend Container" {
        [Express.js Server] as Express
        [Prisma ORM] as Prisma
        [Threat Engine] as Engine
        [AI Service Adapter] as AIService
        Express *-- Engine
        Express *-- AIService
        Express *-- Prisma
    }

    package "Data Layer" {
        database "PostgreSQL 16" as DB {
            [Logs Table]
            [Users Table]
            [Alerts Table]
        }
    }

    package "AI Layer" {
        [Ollama Service] as Ollama
        [LLM Model: qwen2.5] as Model
        Ollama *-- Model
    }
}

cloud "External World" {
    [Admin Browser] as Client
    [Log Sources] as Sources
}

Client --> NextJS : HTTPS / Port 3000
Sources --> Express : HTTP POST /api/logs / Port 3001
NextJS --> Express : REST API Requests
Express --> DB : SQL Queries (Prisma)
Express --> Ollama : JSON Inference Req
@enduml
\end{lstlisting}

\section{Sequence Diagram: AI Chat RAG}
\begin{lstlisting}
@startuml sequence_chat_rag
actor Analyst
participant "Chat Interface" as UI
participant "Backend Service" as Backend
participant "Prisma DB" as DB
participant "Ollama AI" as AI

Analyst -> UI : "Why can't users login?"
activate UI
UI -> Backend : POST /api/chat {message}
activate Backend

group RAG Context Retrieval
    Backend -> DB : Query: SELECT logs WHERE error=true
    activate DB
    DB --> Backend : List of Login Failed Logs
    deactivate DB
end

Backend -> Backend : Build Prompt (System Role + Logs + Query)

Backend -> AI : POST /api/generate {prompt}
activate AI
AI -> AI : Inference (Thinking...)
AI --> Backend : "Multiple failed login attempts detected..."
deactivate AI

Backend -> DB : Save Chat History
Backend --> UI : Return AI Response
deactivate Backend

UI -> Analyst : Display Response
deactivate UI
@enduml
\end{lstlisting}

\section{Activity Diagram: Threat Detection}
\begin{lstlisting}
@startuml activity_threat_detection
start
:Log Received via API;
:Parse Log Content;
:Validate Schema (Zod);

partition "Threat Engine" {
    if (Matches "SQL Injection" Pattern?) then (yes)
        :Tag as CRITICAL;
        :Create "Security Alert";
    elseif (Matches "Brute Force" Pattern?) then (yes)
        :Tag as HIGH;
        :Increment Failed Login Counter;
        if (Counter > Threshold?) then (yes)
             :Create "Brute Force Alert";
        endif
    elseif (Is System Error?) then (yes)
        :Tag as WARNING;
    else (no)
        :Tag as INFO;
    endif
}

:Save to Database (Prisma);
:Broadcast to Dashboard (WebSocket/SSE);
stop
@enduml
\end{lstlisting}

\section{Sequence Diagram: Login}
\begin{lstlisting}
@startuml sequence_login
actor User
participant "Next.js UI" as UI
participant "Backend API" as API
database "PostgreSQL" as DB

User -> UI : Enter Email & Password
activate UI
UI -> API : POST /api/auth/login
activate API
API -> DB : Find User by Email
activate DB
DB --> API : User Record (Hash)
deactivate DB

API -> API : Compare Password Hash
alt Password Valid
    API -> API : Generate JWT Token
    API --> UI : 200 OK + Token + UserData
    UI -> UI : Store Token (Context/Cookie)
    UI -> User : Redirect to Dashboard
else Password Invalid
    API --> UI : 401 Unauthorized
    UI -> User : Show Error Message
end
deactivate API
deactivate UI
@enduml
\end{lstlisting}

\printbibliography[heading=bibintoc]


\end{document}
