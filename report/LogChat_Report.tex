\documentclass[12pt, a4paper]{report}

% =========================================================================
% PACKAGES
% =========================================================================
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{titlesec}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{array}
\usepackage{fancyhdr}
\usepackage{tocbibind}
\usepackage[backend=biber, style=ieee]{biblatex}
\usepackage{csquotes}
\usepackage{tcolorbox} % For "Beginner Note" boxes
\usepackage{enumitem}

\addbibresource{references.bib}

% =========================================================================
% PAGE CONFIGURATION
% =========================================================================
\geometry{
    a4paper, 
    left=25mm, 
    right=25mm, 
    top=25mm, 
    bottom=25mm
}
\linespread{1.5} % Good for length and readability

% Header/Footer
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\slshape \rightmark}
\fancyhead[R]{\thepage}
\renewcommand{\headrulewidth}{0.4pt}

% Colors
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\definecolor{infoboxcolor}{rgb}{0.9,0.95,1.0}

% Code Listing Style
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}

% Command for Placeholder Images
\newcommand{\placeholderImage}[2]{
    \begin{figure}[H]
        \centering
        \fbox{
            \begin{minipage}{0.9\textwidth}
                \centering
                \vspace{2cm}
                \textbf{PLACEHOLDER FOR:} #1 \\
                \textit{(Screenshot/Diagram)}
                \vspace{2cm}
            \end{minipage}
        }
        \caption{#2}
        \label{fig:#1}
    \end{figure}
}

% Beginner Friendly Note Box
\newtcolorbox{infobox}[1]{
    colback=infoboxcolor,
    colframe=blue!30!black,
    title=\textbf{#1},
    fonttitle=\bfseries
}

% =========================================================================
% DOCUMENT BEGINS
% =========================================================================
\begin{document}

% -------------------------------------------------------------------------
% TITLE PAGE
% -------------------------------------------------------------------------
\begin{titlepage}
    \begin{center}
        \includegraphics[width=4cm]{placeholder_logo.png} \\ % Placeholder for uni/project logo
        \vspace{1cm}
        {\Large \textbf{Higher Institute of Technological Studies}}\\[0.5cm]
        {\large Department of Computer Technologies}\\[2cm]

        {\Huge \textbf{LogChat: AI-Powered SIEM Platform}}\\[0.5cm]
        {\Large \textit{An Intelligent Security Information and Event Management System}}\\[2cm]

        \textbf{End of Year Project Report}\\[2cm]

        \begin{minipage}{0.4\textwidth}
            \begin{flushleft} \large
                \emph{Authors:}\\
                Saleh Eddine \textsc{Touil}\\
                Chames Edin \textsc{Turki}
            \end{flushleft}
        \end{minipage}
        \begin{minipage}{0.4\textwidth}
            \begin{flushright} \large
                \emph{Supervisor:}\\
                Mr. Mounir \textsc{Kthiri}
            \end{flushright}
        \end{minipage}

        \vfill
        {\large Academic Year: 2024 - 2025}
    \end{center}
\end{titlepage}

% -------------------------------------------------------------------------
% FRONT MATTER
% -------------------------------------------------------------------------
\section*{Dedication}
\textit{To our families, for their endless support and coffee supplies. To the open-source community, for giving us the blocks to build our castle.}
\newpage

\section*{Acknowledgements}
We would like to express our deepest gratitude to our supervisor, Mr. Mounir Kthiri, for his guidance, patience, and technical insights throughout this project.
We also thank our friends and colleagues who helped test the platform and provided valuable feedback.
\newpage

\section*{Abstract}
In the modern cybersecurity landscape, logs are generated at an unprecedented rate. Traditional Security Information and Event Management (SIEM) systems are often expensive, complex to deploy, and lack intuitive interfaces for non-expert users.

\textbf{LogChat} addresses this gap by combining a robust logging architecture with the power of Generative AI (Large Language Models). Built with Next.js, Node.js, and PostgreSQL, and integrated with Ollama (local LLM), LogChat allows security analysts to "chat" with their logs. Instead of writing complex SQL or KQL queries, users can ask "What security threats happened today?" and receive an AI-synthesized answer based on real database records.

This report details the full development lifecycle, from state-of-the-art analysis and requirements gathering to architectural design, full-stack implementation, and containerized deployment.

\vspace{1cm}
\textbf{Keywords:} SIEM, Cybersecurity, Artificial Intelligence, LLM, RAG, React, Docker, Threat Detection.
\newpage

\tableofcontents
\listoffigures
\listoftables
\newpage

% -------------------------------------------------------------------------
% GENERAL INTRODUCTION
% -------------------------------------------------------------------------
\chapter*{General Introduction}
\addcontentsline{toc}{chapter}{General Introduction}

\section*{Context}
Every server, application, and network device generates "logs"—records of what happened, when, and by whom. In small systems, a system administrator might manually read a text file to check for errors. However, in enterprise environments generating millions of logs per hour, manual inspection is impossible. This is where \textbf{SIEM} (Security Information and Event Management) systems come in. They aggregate logs, detect patterns, and alert administrators to threats.

However, a new problem has emerged: "Alert Fatigue" and high technical barriers. Using tools like Splunk or ELK Stack requires learning complex query languages. If an attacker breaches a system, finding the needle in the haystack requires expertise.

\section*{Problem Statement}
\begin{itemize}
    \item \textbf{High Complexity:} Existing tools are hard to configure and query.
    \item \textbf{Data Overload:} Security teams are overwhelmed by raw data without context.
    \item \textbf{Lack of AI Integration:} Most open-source SIEMs rely on static rule-matching (Regular Expressions) and lack semantic understanding of threats.
\end{itemize}

\section*{Proposed Solution: LogChat}
Our project, \textbf{LogChat}, proposes a paradigm shift. Instead of just searching logs, you verify them with an AI.
\begin{itemize}
    \item \textbf{Centralized Logging:} A HTTP API to ingest logs from any source.
    \item \textbf{Real-time Dashboards:} Visualizing system health and security events.
    \item \textbf{Threat Engine:} Automatic rule-based tagging of logs (e.g., stopping SQL Injection attempts).
    \item \textbf{RAG Chatbot:} A "Retrieval Augmented Generation" system where an AI answers questions using your live log data as context.
\end{itemize}

\section*{Report Structure}
This report is organized into four main chapters:
\begin{enumerate}
    \item \textbf{State of the Art:} Comparing existing solutions and selecting technologies.
    \item \textbf{Analysis and Design:} Detailed requirements, UML diagrams, and architecture.
    \item \textbf{Implementation:} Deep dive into the code, database interaction, and AI integration.
    \item \textbf{Testing and Deployment:} Validating the system quality and deploying via Docker.
\end{enumerate}

\begin{infobox}{Beginner Concept: What is a Log?}
    A log is like a "black box" recording for computers. It is a text message that a program writes when something occurs. For example:
    \texttt{[2024-05-20 10:00:00] [ERROR] User 'admin' failed to login (Wrong Password).}
    Collecting these helps us detect hackers!
\end{infobox}

\cleardoublepage

% =========================================================================
% CHAPTER 1: STATE OF THE ART
% =========================================================================
\chapter{State of the Art}

\section{Introduction}
Before building LogChat, we must understand the current landscape of logging and security monitoring tools. This chapter explores market leaders, theoretical concepts of SIEM, and justifies our technology choices.

\section{Understanding SIEM Systems}
SIEM stands for \textbf{Security Information and Event Management}. It aggregates log data from various sources (servers, firewalls, applications), identifies patterns that signify threats, and alerts security teams.

\begin{infobox}{What does a SIEM do?}
    Imagine a security guard watching 100 CCTV cameras at once. A SIEM is the computer that automatically beeps when it sees someone breaking a window on Camera 42.
\end{infobox}

\section{Existing Solutions Comparison}

\subsection{Splunk}
Splunk is the market leader. It allows capturing, indexing, and correlating real-time data in a searchable repository.
\begin{itemize}
    \item \textbf{Pros:} extremely powerful, vast ecosystem of plugins, beautiful dashboards.
    \item \textbf{Cons:} Extremely expensive (proprietary license), high hardware requirements, steep learning curve (SPL language).
\end{itemize}

\subsection{ELK Stack (Elasticsearch, Logstash, Kibana)}
The Elastic Stack is the most popular open-source option.
\begin{itemize}
    \item \textbf{Pros:} Open-source core, scalable, industry standard.
    \item \textbf{Cons:} Very resource-heavy (Java-based), complex to manage at scale, no built-in "AI Chat".
\end{itemize}

\subsection{Wazuh}
Wazuh is an open-source security platform (unifying XDR and SIEM).
\begin{itemize}
    \item \textbf{Pros:} Great for endpoint security, pre-configured rules.
    \item \textbf{Cons:} UI can be clunky, focused more on Host IDS than application logs.
\end{itemize}

\subsection{Comparison Table}
\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Feature} & \textbf{Splunk} & \textbf{ELK Stack} & \textbf{LogChat (Ours)} \\ \hline
License & Commercial & Open Core & MIT (Open Source) \\ \hline
Cost & \$\$\$\$ & \$\$ (Hosting) & \$ (Low Resource) \\ \hline
AI Integration & Add-on & ML Nodes & \textbf{Native Core Feature} \\ \hline
Ease of Use & Hard & Medium & \textbf{Easy (Chat-based)} \\ \hline
Architecture & Proprietary & Java/NoSQL & Node.js/PostgreSQL \\ \hline
\end{tabular}
\caption{Comparison of SIEM Solutions}
\end{table}

\section{The Rise of Generative AI in Ops}
The newest trend in 2024 is \textbf{AIOps}. Large Language Models (LLMs) like GPT-4 or Llama 3 can understand code and logs. By integrating an LLM, we lower the barrier to entry. This technique is often called **RAG** (Retrieval Augmented Generation).

\begin{infobox}{What is RAG?}
    LLMs (like ChatGPT) don't know your private data. RAG is a technique where we search your database for relevant info first, then give it to the AI saying "Use this info to answer the user's question."
\end{infobox}

\section{Technology Stack Selection}
For LogChat, we chose a modern, lightweight, and JavaScript-centric stack.

\subsection{Frontend: Next.js 14}
\begin{itemize}
    \item \textbf{Why?} React-based framework with Server Side Rendering (SSR). Excellent performance and developer experience.
    \item \textbf{Role:} Admin Dashboard, Real-time Charts, Chat Interface.
\end{itemize}

\subsection{Backend: Node.js \& Express}
\begin{itemize}
    \item \textbf{Why?} Fast I/O, perfect for handling thousands of log requests per minute. Same language (TypeScript) as frontend.
    \item \textbf{Role:} API endpoints, Threat Detection Logic, Auth.
\end{itemize}

\subsection{Database: PostgreSQL \& Prisma}
\begin{itemize}
    \item \textbf{Why?} Reliability. SQL is structured and powerful for analytics. Prisma provides type-safe database access.
    \item \textbf{Role:} Storing User profiles, Log events, and Chat history.
\end{itemize}

\subsection{AI Engine: Ollama}
\begin{itemize}
    \item \textbf{Why?} Runs LLMs \textbf{locally}. We don't want to send sensitive security logs to the cloud (privacy risk).
    \item \textbf{Role:} Processing natural language queries into insights.
\end{itemize}

\section{Development Methodology: SCRUM}
We adopted an Agile SCRUM approach.
\begin{itemize}
    \item \textbf{Sprints:} 1-week cycles.
    \item \textbf{Daily Standups:} Brief Discord calls to sync on progress.
    \item \textbf{Tools:} Trello for Kanban, GitHub for version control.
\end{itemize}

\placeholderImage{gantt_chart.png}{Project Gantt Chart Timeline}

\section{Conclusion}
We have identified a gap in the market for a lightweight, AI-first SIEM. We have selected a robust stack (Next.js/Node/Postgres/Ollama) to build it. Next, we will analyze the specific requirements.

\cleardoublepage

% =========================================================================
% CHAPTER 2: ANALYSIS AND DESIGN
% =========================================================================
\chapter{Analysis and Design}

\section{Introduction}
This chapter bridges the gap between the idea and the code. We define \textit{what} the system must do (requirements) and \textit{how} it will be structured (architecture).

\section{Requirement Specification}

\subsection{Functional Requirements}
Functionalities the user interacts with directly:
\begin{enumerate}
    \item \textbf{Log Ingestion:} The system must accept JSON logs via HTTP POST.
    \item \textbf{Threat Detection:} Incoming logs must be scanned for patterns (e.g., 'SQL Syntax Error').
    \item \textbf{Dashboarding:} Real-time counters for Total Logs, Error Rates, and Threat Levels.
    \item \textbf{Chat Assistant:} Users must be able to ask questions in plain English.
    \item \textbf{User Management:} Admin can create analyst accounts.
\end{enumerate}

\subsection{Non-Functional Requirements}
Qualities of the system:
\begin{enumerate}
    \item \textbf{Performance:} Must handle at least 100 logs/second without crashing.
    \item \textbf{Security:} Logs must be protected behind authentication (JWT).
    \item \textbf{Usability:} Dark mode UI, responsive design.
    \item \textbf{Privacy:} AI processing must occur locally (no data leaving the server).
\end{enumerate}

\section{Use Case Analysis}
The Use Case diagram identifies the main actors and their interactions.

\subsection{Actors}
\begin{itemize}
    \item \textbf{Security Analyst (User):} Reviews logs, investigates alerts, chats with AI.
    \item \textbf{Administrator:} Configuring system sources, managing users.
    \item \textbf{External System (Log Source):} A server/app sending log data automatically.
\end{itemize}

\subsection{Global Use Case Diagram}
\placeholderImage{usecase_global.png}{Global Use Case Diagram}
\textit{Figure shows Users logging in, viewing dashboards, and Systems pushing logs automatically.}

\section{System Architecture}
We chose a \textbf{Dockerized Microservices-like} architecture. While essentially a monolith in logic, the services are containerized separately.

\subsection{Component Diagram}
The architecture separates the User Interface from the Logic and Data.

\placeholderImage{architecture_component.png}{System Component Architecture}

\begin{infobox}{Why Containers?}
    Docker containers wrap our software with everything it needs to run. This ensures that LogChat works on my laptop, your laptop, and the production server exactly the same way.
\end{infobox}

\section{Sequence Diagrams}
To understand the flow of data, we model specific scenarios.

\subsection{Scenario 1: User Login}
\placeholderImage{sequence_login.png}{Sequence Diagram: User Authentication}
The user sends credentials, the backend validates against PostgreSQL, and issues a JWT (JSON Web Token).

\subsection{Scenario 2: AI Chat (RAG Flow)}
This is the core innovation of our project. 
\begin{enumerate}
    \item User asks "Show me errors".
    \item Backends searches DB for recent logs with level='ERROR'.
    \item Backend formats a prompt: \textit{"Here are the logs: [LOG\_DATA]. QA: Show me errors"}.
    \item Ollama generates a summary.
    \item Backend returns summary to UI.
\end{enumerate}

\placeholderImage{sequence_chat_rag.png}{Sequence Diagram: AI Chat Interaction}

\section{Activity Diagrams}
How does the "Threat Engine" decide if a log is dangerous?

\placeholderImage{activity_threat_detection.png}{Activity Diagram: Log Ingestion \& Threat Logic}

\section{Database Design}
We use a relational model. 

\subsection{Entities}
\begin{itemize}
    \item \textbf{User:} \texttt{id, email, password\_hash, role}
    \item \textbf{Log:} \texttt{id, timestamp, level, message, metadata (JSON)}
    \item \textbf{ChatSession:} \texttt{id, user\_id, title}
    \item \textbf{Message:} \texttt{id, session\_id, role (user/ai), content}
\end{itemize}

\subsection{Class Diagram}
\placeholderImage{class_diagram_domain.png}{Domain Class Diagram}

\section{Conclusion}
We have mapped out the requirements and modeled the system using UML. The design prioritizes modularity and data flow efficiency.

\cleardoublepage

% =========================================================================
% CHAPTER 3: IMPLEMENTATION
% =========================================================================
\chapter{Implementation}

\section{Introduction}
This chapter documents the coding phase. We will look at the project structure, the backend logic, the frontend components, and the integration of the AI model.

\section{Development Environment}
\begin{itemize}
    \item \textbf{OS:} Windows 11 / Linux (Ubuntu 22.04 on Server)
    \item \textbf{IDE:} VS Code with ESLint and Prettier
    \item \textbf{Version Control:} Git \& GitHub
    \item \textbf{API Testing:} Postman \& Thunder Client
\end{itemize}

\section{Backend Implementation}
The backend is the brain of LogChat. It lives in the \texttt{/backend} folder.

\subsection{Project Structure}
\begin{lstlisting}[language=bash]
backend/
|-- src/
|   |-- index.ts          # Entry point
|   |-- services/         # Business Logic
|   |   |-- logs.ts       # Log storage logic
|   |   |-- ollama.ts     # AI wrappers
|   |-- routes/           # API Endpoints
|   |-- prisma/           # Database Schema
|-- Dockerfile
\end{lstlisting}

\subsection{Data Access Layer (Prisma)}
We define our database schema in \texttt{schema.prisma}. This allows us to automatically generate TypeScript types.

\begin{lstlisting}[language=JavaScript, caption=Prisma Schema Snippet]
model Log {
  id        String   @id @default(uuid())
  level     String   // INFO, WARN, ERROR
  message   String
  source    String   // e.g., "PaymentService"
  timestamp DateTime @default(now())
  metadata  Json?    // Flexible JSON storage
}
\end{lstlisting}

\subsection{The Threat Detection Engine}
This service runs on every incoming log. It uses fast string matching (RegEx) to tag suspicious activities. 

\begin{lstlisting}[language=JavaScript, caption=Threat Detection Logic]
// services/threats.ts
const PATTERNS = [
  { name: 'SQL_INJECTION', regex: /' OR '1'='1/i, severity: 'CRITICAL' },
  { name: 'XSS_ATTEMPT', regex: /<script>/i, severity: 'HIGH' },
  { name: 'password_dump', regex: /passwd/i, severity: 'HIGH' }
];

export function scanLog(message: string) {
  for (const pattern of PATTERNS) {
    if (pattern.regex.test(message)) {
      return { detected: true, type: pattern.name };
    }
  }
  return { detected: false };
}
\end{lstlisting}

When a log matches, we mark it as "Flagged" in the database so it appears red in the dashboard.

\section{AI Integration (Ollama)}
This is the most complex part. We communicate with the local LLM running on port 11434.

\subsection{The Prompt Engineering}
We cannot just send the user question to the AI; it doesn't know context. We inject the context dynamically.

\begin{lstlisting}[language=JavaScript, caption=RAG Prompt Construction]
const contextLogs = await prisma.log.findMany({ take: 20 });
const contextString = JSON.stringify(contextLogs);

const prompt = `
SYSTEM: You are a cybersecurity analyst. 
Use the following logs to answer the user.
LOGS: ${contextString}

USER QUESTION: ${userMessage}
`;
\end{lstlisting}
This allows the AI to "read" the database before answering.

\section{Frontend Implementation}
The frontend uses Next.js 14 \texttt{App Router}. 

\subsection{Dashboard Page}
The dashboard displays aggregated stats. We use \texttt{useSWR} for data fetching (stale-while-revalidate) to ensure charts update near real-time.

\placeholderImage{dashboard_full.png}{The Main Dashboard UI showing stats cards and charts}

\subsection{Live Log Viewer}
We implemented a table that auto-refreshes. Security analysts can watch logs stream in.

\begin{lstlisting}[language=JavaScript, caption=React Log Table Component]
export default function LogTable({ logs }) {
  return (
    <table className="w-full text-left">
      <thead>
        <tr><th>Time</th><th>Level</th><th>Message</th></tr>
      </thead>
      <tbody>
        {logs.map(log => (
          <tr key={log.id} className={log.level === 'ERROR' ? 'bg-red-100' : ''}>
            <td>{new Date(log.timestamp).toLocaleTimeString()}</td>
            <td>{log.level}</td>
            <td>{log.message}</td>
          </tr>
        ))}
      </tbody>
    </table>
  );
}
\end{lstlisting}

\placeholderImage{log_table_view.png}{The Log Explorer Interface}

\subsection{The Chat Interface}
A familiar chat UI (like ChatGPT). It maintains state of the conversation array.

\placeholderImage{chat_interface.png}{Chat Interface interacting with Log Data}

\section{Docker Implementation}
To simplify deployment, we use \texttt{docker-compose.yml}.

\begin{lstlisting}[language=yml, caption=Docker Compose Configuration]
services:
  backend:
    build: ./backend
    ports: ["3001:3001"]
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/logs
  
  frontend:
    build: ./frontend
    ports: ["3000:3000"]

  ollama:
    image: ollama/ollama
    volumes:
      - ollama_data:/root/.ollama
\end{lstlisting}

\section{Conclusion}
The implementation phase successfully delivered a functional MVP (Minimum Viable Product). The pieces—Database, API, UI, and AI—talk to each other seamlessly within the Docker network.

\cleardoublepage

% =========================================================================
% CHAPTER 4: TESTING AND DEPLOYMENT
% =========================================================================
\chapter{Testing and Deployment}

\section{Introduction}
Writing code is not enough; it must be verified. This chapter covers the testing strategy and how we deploy the solution.

\section{Testing Strategy}
We employed a "Testing Pyramid" approach: Unit Tests (small), Integration Tests (connected), and Manual/E2E Tests (full flow).

\subsection{Unit Testing (Manual Verification)}
We verified the threat detection regexes individually.
\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Input String} & \textbf{Expected Result} & \textbf{Pass/Fail} \\ \hline
"User logged in" & Safe & Pass \\ \hline
"SELECT * FROM users" & SQL Injection (Critical) & Pass \\ \hline
"<script>alert(1)</script>" & XSS Threat (High) & Pass \\ \hline
\end{tabular}
\caption{Threat Engine Test Cases}
\end{table}

\subsection{Integration Testing}
We tested the API endpoints using Postman.
\begin{itemize}
    \item \textbf{POST /api/logs:} Valid JSON returns 201 Created. Invalid JSON returns 400 Bad Request.
    \item \textbf{GET /api/stats:} Verifying the counters match the number of rows in DB.
\end{itemize}

\section{Deployment Guide}
We deploy using Docker.

\placeholderImage{deployment_diagram.png}{Deployment Diagram}

\subsection{Prerequisites}
\begin{itemize}
    \item A machine with 8GB RAM (for AI model).
    \item Docker Desktop or Docker Engine installed.
\end{itemize}

\subsection{Launch Steps}
\begin{enumerate}
    \item Clone the repository.
    \item Run \texttt{docker-compose up --build}.
    \item Wait for the AI model to pull (approx 2GB).
    \item Access \texttt{localhost:3000}.
\end{enumerate}

\section{Challenges Faced}
\begin{enumerate}
    \item \textbf{LLM Latency on CPU:} Running Ollama on a laptop CPU is slow (3-4 seconds per reply). In production, a GPU is recommended.
    \item \textbf{Docker Networking:} Connecting the Backend container to the Ollama container required careful DNS configuration in docker-compose.
\end{enumerate}

\section{Future Improvements}
\begin{itemize}
    \item \textbf{Kubernetes Support:} For high availability scaling.
    \item \textbf{Fine-Tuning:} Training the specific AI model on cybersecurity datasets to improve accuracy.
    \item \textbf{Dark Mode:} Fully implementing theme switching.
\end{itemize}

\section{Conclusion}
The system is stable, easy to deploy, and meets the core requirements defined in Chapter 2.

\cleardoublepage

% =========================================================================
% CHAPTER 5: USER GUIDE (Tutorial)
% =========================================================================
\chapter{User Guide \& Walkthrough}
\label{chap:userguide}

\section{Welcome to LogChat}
This section is a pictorial guide for new users.

\section{1. The Login Screen}
When you first open the app, you must authenticate.
\placeholderImage{login_page.png}{The Secure Login Page}

\section{2. The Dashboard}
After login, you see the "Mission Control".
\placeholderImage{dashboard_after_seed.png}{Dashboard populated with data}
\begin{itemize}
    \item \textbf{Top Row:} Critical Alerts count.
    \item \textbf{Charts:} Log volume over time.
    \item \textbf{Gauge:} Access Log vs Error Log ratio.
\end{itemize}

\section{3. Exploring Logs}
Click "Logs" in the sidebar. You can filter by:
\begin{itemize}
    \item Level (Info, Error, Warn)
    \item Source (Frontend, API, Auth)
    \item Search Text
\end{itemize}
\placeholderImage{log_table_view.png}{Filtering logs for specific errors}

\section{4. Chatting with your Data}
Click "AI Assistant". Try typing: \textit{"Summarize the last 5 errors"}.
\placeholderImage{chat_first_question.png}{The AI response summarizing database rows}

\begin{infobox}{Tip: Be specific!}
    The AI works best with clear questions. Instead of "What's up?", ask "Are there any SQL injection attempts in the last hour?"
\end{infobox}

\cleardoublepage

% =========================================================================
% GENERAL CONCLUSION
% =========================================================================
\chapter*{General Conclusion}
\addcontentsline{toc}{chapter}{General Conclusion}

\section*{Summary}
This project set out to democratize access to advanced security monitoring using the latest advancements in Artificial Intelligence. We successfully built \textbf{LogChat}, a functional SIEM that allows anyone—regardless of technical skill—to query their system's security status using natural language.

\section*{Key Achievements}
\begin{itemize}
    \item \textbf{Full Stack Mastery:} Developed a complete solution using Next.js, Node.js, and Postgres.
    \item \textbf{AI Innovation:} Successfully integrated a local LLM (Ollama) into a production workflow using RAG.
    \item \textbf{User Experience:} Created a clean, intuitive interface that hides the complexity of log management.
\end{itemize}

\section*{Personal Reflections}
Working on LogChat was a journey of discovery. We learned that integrating AI is not magic; it requires rigorous data engineering (RAG) to be useful. We also gained deep appreciation for the stability of Docker in development workflows.

We believe LogChat represents the future of specialized software: tools that don't just display data, but help you \textit{understand} it.


% =========================================================================
% APPENDIX A: DIAGRAM SOURCE CODES
% =========================================================================
\appendix
\chapter{Appendix: PlantUML Source Codes}
For transparency and reproducibility, we include the source code for the diagrams used in this report. These can be rendered using any PlantUML-compatible tool.

\section{Use Case Diagram: Global}
\begin{lstlisting}
@startuml usecase_global
left to right direction
actor "Security Analyst" as Analyst
actor "System Administrator" as Admin
actor "Background System" as System

rectangle "LogChat SIEM Platform" {
    package "Core Operations" {
        usecase "Authenticate (Login/Logout)" as UC1
        usecase "View Analytics Dashboard" as UC2
        usecase "Explore & Filter Logs" as UC3
        usecase "Chat with AI Assistant" as UC4
    }

    package "Administration" {
        usecase "Manage Users & Roles" as UC5
        usecase "Configure Log Sources" as UC6
        usecase "Manage Alert Rules" as UC7
        usecase "View Audit Logs" as UC8
    }

    package "Automated Processes" {
        usecase "Ingest Logs via API" as UC9
        usecase "Detect Threats (Real-time)" as UC10
        usecase "Trigger Alerts" as UC11
    }
}

Analyst --> UC1
Analyst --> UC2
Analyst --> UC3
Analyst --> UC4
Analyst --> UC8

Admin --> UC1
Admin --> UC5
Admin --> UC6
Admin --> UC7
Admin --> UC8

System --> UC9
System --> UC10
System --> UC11
UC10 .> UC11 : <<include>>
@enduml
\end{lstlisting}

\section{Component Architecture}
\begin{lstlisting}
@startuml architecture_component
skinparam componentStyle uml2

package "Docker Container Host" {
    package "Frontend Container" {
        [Next.js App Router] as NextJS
        [React Components] as React
        [Tailwind CSS] as UI
        NextJS *-- React
        React *-- UI
    }

    package "Backend Container" {
        [Express.js Server] as Express
        [Prisma ORM] as Prisma
        [Threat Engine] as Engine
        [AI Service Adapter] as AIService
        Express *-- Engine
        Express *-- AIService
        Express *-- Prisma
    }

    package "Data Layer" {
        database "PostgreSQL 16" as DB {
            [Logs Table]
            [Users Table]
            [Alerts Table]
        }
    }

    package "AI Layer" {
        [Ollama Service] as Ollama
        [LLM Model: qwen2.5] as Model
        Ollama *-- Model
    }
}

cloud "External World" {
    [Admin Browser] as Client
    [Log Sources] as Sources
}

Client --> NextJS : HTTPS / Port 3000
Sources --> Express : HTTP POST /api/logs / Port 3001
NextJS --> Express : REST API Requests
Express --> DB : SQL Queries (Prisma)
Express --> Ollama : JSON Inference Req
@enduml
\end{lstlisting}

\section{Sequence Diagram: AI Chat RAG}
\begin{lstlisting}
@startuml sequence_chat_rag
actor Analyst
participant "Chat Interface" as UI
participant "Backend Service" as Backend
participant "Prisma DB" as DB
participant "Ollama AI" as AI

Analyst -> UI : "Why can't users login?"
activate UI
UI -> Backend : POST /api/chat {message}
activate Backend

group RAG Context Retrieval
    Backend -> DB : Query: SELECT logs WHERE error=true
    activate DB
    DB --> Backend : List of Login Failed Logs
    deactivate DB
end

Backend -> Backend : Build Prompt (System Role + Logs + Query)

Backend -> AI : POST /api/generate {prompt}
activate AI
AI -> AI : Inference (Thinking...)
AI --> Backend : "Multiple failed login attempts detected..."
deactivate AI

Backend -> DB : Save Chat History
Backend --> UI : Return AI Response
deactivate Backend

UI -> Analyst : Display Response
deactivate UI
@enduml
\end{lstlisting}

\printbibliography[heading=bibintoc]


\end{document}
